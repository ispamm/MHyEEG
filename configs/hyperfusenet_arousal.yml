# Model
model: "HyperFuseNet"
n: 4 # For PHM layers
dropout_rate: 0.1789

# Training
epochs: 50
patience: 20
train_batch_size: 8
test_batch_size: 8

# OneCycleLR scheduler params
min_mom: 0.7403
max_mom: 0.7985
max_lr: 0.00000796
div_factor: 10
final_div_factor: 10
pct_start: 0.425
